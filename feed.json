{
    "version": "https://jsonfeed.org/version/1",
    "title": "",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2025/06/15/AI/week8-9/",
            "url": "http://example.com/2025/06/15/AI/week8-9/",
            "title": "Week8-9",
            "date_published": "2025-06-14T16:00:00.000Z",
            "content_html": "<h1 id=\"K-Means\"><a href=\"#K-Means\" class=\"headerlink\" title=\"K-Means\"></a>K-Means</h1><p>������������ν�n���������������ƶȴ�С�����Ƿֱ���ൽk�����ϣ�ʹ��ÿ�����ݽ�����һ�����༯�ϡ�</p>\n<ul>\n<li>��ʼ�����ģ����ѡ��k�����ݵ���Ϊ��ʼ����$c_1, c_2, …, c_k$��</li>\n<li>�������ݵ㣺����ÿ�����ݵ�$x_i$�����������������ĵľ��룬��������䵽����������������ڵĴ���</li>\n<li>�������ģ�����ÿ���أ�����ô����������ݵ��ƽ��ֵ������ƽ��ֵ��Ϊ�µ����ġ�</li>\n<li>�������̣��ظ�ִ�з���͸��²��裬ֱ�����Ĳ��ٷ����仯��ﵽԤ���������������</li>\n</ul>\n<h1 id=\"���ɷַ���-PCA\"><a href=\"#���ɷַ���-PCA\" class=\"headerlink\" title=\"���ɷַ���(PCA)\"></a>���ɷַ���(PCA)</h1><ul>\n<li>���룺n��dά�������������ɵľ���$\\mathbf{X}$����ά���ά��l</li>\n<li>�����ӳ�����$\\mathbf{W} &#x3D; {\\mathbf{w}_1, \\mathbf{w}_2, …, \\mathbf{w}_l}$<br>�㷨���裺</li>\n</ul>\n<ol>\n<li><p>����ÿ����������$\\mathbf{x}_i$�������Ļ�������<br>$$<br>\\mathbf{x}_i’ &#x3D; \\mathbf{x}<em>i - \\mu, \\quad \\mu &#x3D; \\frac{1}{n}\\sum</em>{j&#x3D;1}^{n} \\mathbf{x}_j<br>$$</p>\n</li>\n<li><p>����ԭʼ�������ݵ�Э�������<br>$$<br>\\Sigma &#x3D; \\frac{1}{n-1} \\mathbf{X}^T \\mathbf{X}<br>$$</p>\n</li>\n<li><p>��Э�������$\\Sigma$��������ֵ�ֽ⣬����������������ֵ��С����$\\lambda_1 \\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_d$</p>\n</li>\n<li><p>ȡǰ$l$���������������Ӧ��������$\\mathbf{w}_1, \\mathbf{w}_2, …, \\mathbf{w}_l$���ӳ�����$\\mathbf{W}$</p>\n</li>\n<li><p>��ÿ����������$\\mathbf{x}<em>i$�������·�����ά��<br>$$<br>(\\mathbf{x}<em>i)</em>{1 \\times d} (\\mathbf{W})</em>{d \\times l} &#x3D; 1 \\times l<br>$$<br>���֣�</p>\n<table>\n<thead>\n<tr>\n<th>ά��</th>\n<th>PCA</th>\n<th>LDA</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>����</strong></td>\n<td>�޼ල</td>\n<td>�мල</td>\n</tr>\n<tr>\n<td><strong>Ŀ��</strong></td>\n<td>��󻯷��������Ҫ�ֲ���Ϣ</td>\n<td>��������룬��С�����ھ���</td>\n</tr>\n<tr>\n<td><strong>�Ƿ�ʹ�������Ϣ</strong></td>\n<td>? ��ʹ��</td>\n<td>? ʹ��</td>\n</tr>\n<tr>\n<td><strong>��������</strong></td>\n<td>����ѹ�������ӻ���ȥ��</td>\n<td>���������������ȡ</td>\n</tr>\n<tr>\n<td><strong>��ά��ά������</strong></td>\n<td>�����⣬��һ��С��ԭά��</td>\n<td>��ཱུ�� $k-1$ ά��$k$ ���������</td>\n</tr>\n<tr>\n<td><strong>��ѧ����</strong></td>\n<td>Э������������ֵ�ֽ�</td>\n<td>���&#x2F;����ɢ�Ⱦ���Ĺ�������ֵ�ֽ�</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n<ul>\n<li>������ά������<ul>\n<li>�Ǹ�����ֽ� ��non-negative matrix factorization, NMF��</li>\n<li>��ά�߶ȷ���Metric multidimensional scaling, MDS��</li>\n<li>�ֲ�����Ƕ�루Locally Linear Embedding��LLE��</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"������������\"><a href=\"#������������\" class=\"headerlink\" title=\"������������\"></a>������������</h1><p>����ʱ��ÿ������ͼ��ת����������<br><img data-src=\"/f1.jpg\"><br>�㷨����</p>\n<ul>\n<li>���룺$n$��1024ά�����������������ɵľ���$\\mathbf{X}$����ά���ά��$l$</li>\n<li>�����ӳ�����$\\mathbf{W} &#x3D; {\\mathbf{w}_1, \\mathbf{w}_2, …, \\mathbf{w}_l}$������ÿ��$\\mathbf{w}_j (1 \\leq j \\leq l)$��һ������������<br>�㷨����</li>\n</ul>\n<ol>\n<li><p>���Ļ�������</p>\n<ul>\n<li>��ÿ��������������$x_i$�������Ļ�������<br>$$<br>x_i’ &#x3D; x_i - \\mu, \\quad \\mu &#x3D; \\frac{1}{n}\\sum_{j&#x3D;1}^{n} x_j<br>$$</li>\n</ul>\n</li>\n<li><p>����Э�������</p>\n<ul>\n<li>����ԭʼ�����������ݵ�Э�������<br>$$<br>\\Sigma &#x3D; \\frac{1}{n-1} \\mathbf{X}^T \\mathbf{X}<br>$$</li>\n</ul>\n</li>\n<li><p>����ֵ�ֽ⣺</p>\n<ul>\n<li>��Э�������$\\Sigma$��������ֵ�ֽ⣬���������������Ӵ�С����<br>$$<br>\\lambda_1 \\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_d<br>$$</li>\n</ul>\n</li>\n<li><p>����ӳ�����</p>\n<ul>\n<li>ȡǰ$l$���������������Ӧ��������$\\mathbf{w}_1, \\mathbf{w}_2, …, \\mathbf{w}_l$���ӳ�����$\\mathbf{W}$��</li>\n</ul>\n</li>\n<li><p>���ݽ�ά��</p>\n<ul>\n<li>��ÿ������ͼ��$x_i$�������·�����ά��<br>$$<br>(\\mathbf{x}<em>i)</em>{1 \\times d} (\\mathbf{W})_{d \\times l} &#x3D; 1 \\times l<br>$$<br>����ʵ�õ���pca�����һ�����������ʱ���32*32��ͼ̯����1024*1�����������ѣ�</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"DZ�����������Latent-Semantic-Analysis-LSA��\"><a href=\"#DZ�����������Latent-Semantic-Analysis-LSA��\" class=\"headerlink\" title=\"Ǳ�����������Latent Semantic Analysis, LSA��\"></a>Ǳ�����������Latent Semantic Analysis, LSA��</h1><p>����</p>\n<ol>\n<li><p>��������-�ĵ�����</p>\n<ul>\n<li>����һ������-�ĵ�����$A$������ÿ��Ԫ��$a_{ij}$��ʾ��$i$�������ڵ�$j$���ĵ��е�Ƶ�ʣ�ͨ��ʹ�ô�Ƶ-���ĵ�Ƶ��TF-IDF���м�Ȩ����</li>\n</ul>\n</li>\n<li><p>����ֵ�ֽ⣨SVD����</p>\n<ul>\n<li>�Ե���-�ĵ�����$A$��������ֵ�ֽ⣬��$A &#x3D; U \\Sigma V^T$������$U$��$V$�ֱ���������������������������ɵľ���$\\Sigma$�ǶԽǾ�����Խ����ϵ�Ԫ����$A$������ֵ�����������У���</li>\n</ul>\n</li>\n<li><p>ѡ��ǰ$k$���������ֵ����Ӧ������������</p>\n<ul>\n<li>ѡȡǰ$k$����������ֵ�����Ӧ�������������γɵ��ȱƽ�����$A_k &#x3D; U_k \\Sigma_k V_k^T$������$k$��ѡ��ȡ���ڱ�������ԭʼ��Ϣ����ͨ�������ۻ�����׼�����ȷ����</li>\n</ul>\n</li>\n<li><p>�ؽ������ھ������ϵ��</p>\n<ul>\n<li>ʹ��$A_k$����ԭʼ����$A$�����Լ������������ĵ�֮������ƶȣ���Ƥ��ѷ���ϵ�������Ӷ������ĵ�-�ĵ�֮��Ĺ�����ϵ��</li>\n<li>ͬ���أ�Ҳ��������̽������-���ʡ�����-�ĵ����������ϵ��</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"��������㷨��Expectation-Maximization-Algorithm-EM��\"><a href=\"#��������㷨��Expectation-Maximization-Algorithm-EM��\" class=\"headerlink\" title=\"��������㷨��Expectation-Maximization Algorithm, EM��\"></a>��������㷨��Expectation-Maximization Algorithm, EM��</h1><p>EM�㷨��һ�ֵ�����������Ҫ���ں����������ĸ���ģ�Ͳ����������⡣����Ϊ&#x3D;&#x3D;E������������&#x3D;&#x3D;��&#x3D;&#x3D;M������󻯣�&#x3D;&#x3D;��ͨ��������ʽ�ƽ�ģ�Ͳ����������Ȼ����ֵ��</p>\n<p>����</p>\n<ol>\n<li><p>��ʼ��ģ�Ͳ�����</p>\n<ul>\n<li>����Ϊģ�Ͳ����趨��ʼֵ�������˹���ģ���еľ�ֵ������ȣ���</li>\n</ul>\n</li>\n<li><p>E����Expectation Step��������������</p>\n<ul>\n<li>���ڵ�ǰ��ģ�Ͳ����������������ĺ�����ʷֲ�������ÿһ������$x_i$�Ϳ��ܵ�������$z_i$������$p(z_i|x_i, \\theta)$������$\\theta$��ʾ��ǰ��ģ�Ͳ�����</li>\n</ul>\n</li>\n<li><p>M����Maximization Step���������Ȼ�����͸���ģ�Ͳ���</p>\n<ul>\n<li>���ݹ۲�����$x_i$��������$z_i$�ĺ�����ʷֲ������¹���ģ�Ͳ���$\\theta$��������������ݵĶ�����Ȼ����$\\log p(x,z|\\theta)$��������</li>\n</ul>\n</li>\n<li><p>�ظ�E����M����</p>\n<ul>\n<li>�����ظ�ִ��E����M����ֱ��ģ�Ͳ����������ߴﵽԤ���ĵ�������Ϊֹ��</li>\n</ul>\n</li>\n</ol>\n<p>�����û���������Ҷ�����˵</p>\n",
            "tags": [
                "�˹�����"
            ]
        },
        {
            "id": "http://example.com/2025/06/12/AI/week6-7/",
            "url": "http://example.com/2025/06/12/AI/week6-7/",
            "title": "Week6-7",
            "date_published": "2025-06-11T16:00:00.000Z",
            "content_html": "<h1 id=\"Ch4-机器学习\"><a href=\"#Ch4-机器学习\" class=\"headerlink\" title=\"Ch4 机器学习\"></a>Ch4 机器学习</h1><h2 id=\"监督学习\"><a href=\"#监督学习\" class=\"headerlink\" title=\"监督学习\"></a>监督学习</h2><ul>\n<li>标注数据</li>\n<li>学习模型</li>\n<li>损失函数<br>典型的损失函数<br><img data-src=\"/figure2.png\"></li>\n</ul>\n<p>经验风险(empirical risk )</p>\n<ul>\n<li>训练集中数据产生的损失。</li>\n<li>经验风险越小说明学习模型对训练数据拟合程度越好。</li>\n</ul>\n<p>期望风险(expected risk):</p>\n<ul>\n<li>当测试集中存在无穷多数据时产生的损失。</li>\n<li>期望风险越小，学习所得模型越好。</li>\n</ul>\n<p>经验风险最小化</p>\n<p>$$\\min_{f \\in \\Phi} \\frac{1}{n} \\sum_{i&#x3D;1}^{n} Loss(y_i, f(x_i))$$</p>\n<p>期望风险最小化</p>\n<p>$$\\min_{f \\in \\Phi} \\int_{x \\times y} Loss(y, f(x)) P(x, y) dx dy$$</p>\n<p>模型泛化能力与经验风险、期望风险的关系</p>\n<table>\n<thead>\n<tr>\n<th>经验风险小（训练集上表现好）</th>\n<th>期望风险小（测试集上表现好）</th>\n<th>泛化能力强</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>经验风险小（训练集上表现好）</td>\n<td>期望风险大（测试集上表现不好）</td>\n<td>过学习（模型过于复杂）</td>\n</tr>\n<tr>\n<td>经验风险大（训练集上表现不好）</td>\n<td>期望风险大（测试集上表现不好）</td>\n<td>欠学习</td>\n</tr>\n<tr>\n<td>经验风险大（训练集上表现不好）</td>\n<td>期望风险小（测试集上表现好）</td>\n<td>“神仙算法”或“黄粱美梦”</td>\n</tr>\n</tbody></table>\n<p>结构风险最小化 (structural risk minimization)</p>\n<p>为了防止过拟合，在经验风险上加上表示模型复杂度的正则化项 (regularizer) 或惩罚项 (penalty term):</p>\n<p>$$\\min_{f \\in \\Phi} \\frac{1}{n} \\sum_{i&#x3D;1}^{n} Loss(y_i, f(x_i)) + \\lambda J(f)$$</p>\n<ul>\n<li>经验风险: $\\frac{1}{n} \\sum_{i&#x3D;1}^{n} Loss(y_i, f(x_i))$</li>\n<li>模型复杂度: $\\lambda J(f)$</li>\n</ul>\n<p>监督学习方法又可以分为 生成方法 (generative approach) 和 判别方法(discriminative approach)。所学到的模型分别称为生成模型(generative model)和判别模型(discriminative model)<br><img data-src=\"/figure1.png\"></p>\n<h1 id=\"回归分析\"><a href=\"#回归分析\" class=\"headerlink\" title=\"回归分析\"></a>回归分析</h1><h2 id=\"线性回归\"><a href=\"#线性回归\" class=\"headerlink\" title=\"线性回归\"></a>线性回归</h2><ul>\n<li>一元线性回归</li>\n</ul>\n<p>$$y_i &#x3D; ax_i + b \\quad (1 \\leq i \\leq n)$$</p>\n<p>$$a &#x3D; \\frac{\\sum_{i&#x3D;1}^{n} x_i y_i - n \\bar{x} \\bar{y}}{\\sum_{i&#x3D;1}^{n} x_i^2 - n \\bar{x}^2}$$</p>\n<p>$$b &#x3D; \\bar{y} - a \\bar{x}$$</p>\n<ul>\n<li><p>多元线性回归<br>$$f(x_i) &#x3D; a_0 + \\sum_{j&#x3D;1}^{D} a_j x_{i,j} &#x3D; a_0 + \\mathbf{a}^T \\mathbf{x}_i$$<br>a是要求的参数，x是输入的数据，f是预测值。<br>为了方便，使用矩阵来表示所有的训练数据和数据标签。<br>$$X &#x3D; [x_1, …, x_m], \\quad y &#x3D; [y_1, …, y_m]$$<br>最小化均方误差得到：<br>$$a &#x3D; (XX^T)^{-1}X^Ty$$</p>\n</li>\n<li><p>逻辑斯蒂回归&#x2F;对数几率回归<br>线性回归一个明显的问题是对离群点导致模型建模不稳定，使结果有偏，为了缓解这个问题（特别是在二分类场景中）带来的影响，可考虑逻辑斯蒂回归<br>逻辑斯蒂回归就是在回归模型中引入 sigmoid函数的一种非线性回归模型</p>\n</li>\n</ul>\n<h2 id=\"逻辑斯蒂回归-Logistic-Regression\"><a href=\"#逻辑斯蒂回归-Logistic-Regression\" class=\"headerlink\" title=\"逻辑斯蒂回归 (Logistic Regression)\"></a>逻辑斯蒂回归 (Logistic Regression)</h2><p>逻辑斯蒂回归（logistic regression）就是在回归模型中引入 sigmoid 函数的一种非线性回归模型。Logistic 回归模型可如下表示：</p>\n<p>$$ y &#x3D; \\frac{1}{1 + e^{-z}} &#x3D; \\frac{1}{1 + e^{-(w^T x + b)}} $$<br>其中 $y \\in (0, 1)$，$z &#x3D; w^T x + b$。<br>这里 $\\frac{1}{1 + e^{-z}}$ 是 sigmoid 函数，$x \\in \\mathbb{R}^d$ 是输入数据，$w \\in \\mathbb{R}^d$ 和 $b \\in \\mathbb{R}$ 是回归函数的参数。</p>\n<p>逻辑斯蒂回归多用于&#x3D;&#x3D;二分类&#x3D;&#x3D;问题<br>Sigmoid 函数将任意实数映射到区间(0,1)，这正好符合“概率”的取值范围，所以函数的输出y可以被解释为输入数据x属于正例的概率<br>因此我们可以将输出 y 解释为：</p>\n<blockquote>\n<p>在给定输入特征 x 的条件下，该样本属于正类（例如类别 1）的概率。<br>即：<br>$$<br>y &#x3D; P(y &#x3D; 1 \\mid x)<br>$$<br>如果 $P(y&#x3D;1|x)$ 表示给定输入 $x$ 属于正类的概率，则 $1 - P(y&#x3D;1|x)$ 表示属于负类的概率。<br>$\\frac{P(y&#x3D;1|x)}{1 - P(y&#x3D;1|x)}$ 就是正类相对于负类的优势比。所以&gt;1就归为正类，反之就是负类。</p>\n</blockquote>\n<p>$$<br>\\log \\frac{P(y&#x3D;1|x)}{P(y&#x3D;0|x)} &#x3D; {w^T x + b} &gt; \\log{1} &#x3D; 0<br>$$<br>从这里可以看出，logistic回归本质上是一个线性模型。在预测时，可以计算线性函数$w^T x + b$取值是否大于0来判断输入数据x的类别归属</p>\n<p>为了找到最优参数w和b，我们使用最大似然估计，假设每个样本独立同分布，则<br>……<br>公式懒得敲了，</p>\n<p>为什么基于相关性的方法可能会导致模型的不可解释性和不稳定性</p>\n<ul>\n<li>因果特征和非因果特征</li>\n<li>Making V⊥Y: 最终目标是让非因果特征 V 与输出 Y 独立，即消除虚假相关性，使得模型更加稳定和可解释</li>\n</ul>\n<h1 id=\"决策树\"><a href=\"#决策树\" class=\"headerlink\" title=\"决策树\"></a>决策树</h1><p>决策树是一种通过树形结构来进行分类的方法</p>\n<ul>\n<li>信息熵（entropy）是度量样本集合纯度最常用的一种指标<br>假设有一个K个信息（类别），其组成了集合样本D，记第k个信息（类别）发生的概率为$p_k (1 \\leq k \\leq K)$。如下定义这K个信息的信息熵：</li>\n</ul>\n<p>$$Ent(D) &#x3D; -\\sum_{k&#x3D;1}^{K} p_k \\log_2 p_k$$</p>\n<p>&#x3D;&#x3D;$Ent(D)$值越小，表示D包含的信息越确定，也称D的纯度越高。&#x3D;&#x3D;所有$p_k$累加起来的和为1。</p>\n<ul>\n<li>信息增益:衡量使用某个属性进行划分后，数据集不确定性减少的程度<br>得到信息熵后可以进一步计算信息增益：<br>$$Gain(D, A) &#x3D; Ent(D) - \\sum_{i&#x3D;1}^{n} \\frac{|D_i|}{|D|} Ent(D_i)$$<br><img data-src=\"/f3.png\"><br><img data-src=\"/f4.png\"><br>ID3决策树学习算法[Quinlan, 1986]以信息增益为准则来选择划分属性<br>目标：通过不断划分，使得每个子集尽可能“纯净”，即子集内的样本属于同一类</li>\n</ul>\n<p>信息熵（和上面的一样的）<br>$$<br>info &#x3D; -\\sum_{i&#x3D;1}^{n} \\frac{|D_i|}{|D|} \\log_2 \\frac{|D_i|}{|D|}<br>$$</p>\n<p>增益率（Gain-ratio）：</p>\n<p>$$<br>Gain-ratio &#x3D; \\frac{Gain(D, A)}{info}<br>$$<br>存在的问题：增益率准则对可取数目较少的属性有所偏好</p>\n<p>另一种计算更简的度量指标是如下的 Gini 指数（基尼指数）：</p>\n<p>$$<br>Gini(D) &#x3D; 1 - \\sum_{k&#x3D;1}^{K} p_k^2<br>$$</p>\n<p>相对于信息熵的计算 $E(D) &#x3D; -\\sum_{k&#x3D;1}^{K} p_k \\log_2 p_k$，不用计算对数 log，计算更为简易。</p>\n<h2 id=\"连续属性离散化\"><a href=\"#连续属性离散化\" class=\"headerlink\" title=\"连续属性离散化\"></a>连续属性离散化</h2><ol>\n<li><p>确定连续属性的取值范围，确定划分点集合<br>考虑包含 n-1 个元素的候选划分点集合：<br>$$<br>T_a &#x3D; \\left{ \\frac{a^i + a^{i+1}}{2} ,\\middle|, 1 \\leq i \\leq n - 1 \\right}<br>$$<br>这里的每个候选划分点是相邻两个取值的中点，即区间 $[a^i, a^{i+1})$ 的中位点 $\\frac{a^i + a^{i+1}}{2}$</p>\n</li>\n<li><p>计算信息增益<br>$$<br>\\text{Gain}(D, a, t) &#x3D; \\text{Ent}(D) - \\sum_{\\lambda \\in {-, +}} \\frac{|D_t^\\lambda|}{|D|} \\cdot \\text{Ent}(D_t^\\lambda)<br>$$<br>计算每个划分点的信息增益率，选择信息增益最大的划分点</p>\n</li>\n</ol>\n<p>+++info example<br>;;;id3 example<br>给定数据点及其对应的类别标签如下：</p>\n<ul>\n<li>$a_1 &#x3D; 1$ -&gt; 类别为 0</li>\n<li>$a_2 &#x3D; 3$ -&gt; 类别为 1</li>\n<li>$a_3 &#x3D; 5$ -&gt; 类别为 0</li>\n<li>$a_4 &#x3D; 7$ -&gt; 类别为 1</li>\n<li>$a_5 &#x3D; 9$ -&gt; 类别为 0</li>\n</ul>\n<p>因此，我们的数据集 $D$ 是 ${1, 3, 5, 7, 9}$，对应的类别标签分别为 ${0, 1, 0, 1, 0}$。</p>\n<p>第一步：计算原始数据集的信息熵</p>\n<p>$$<br>Ent(D) &#x3D; -\\left( p_0 \\log_2 p_0 + p_1 \\log_2 p_1 \\right)<br>$$</p>\n<p>其中，$p_0 &#x3D; \\frac{3}{5}$，$p_1 &#x3D; \\frac{2}{5}$，则：</p>\n<p>$$<br>Ent(D) &#x3D; -\\left( \\frac{3}{5} \\log_2 \\frac{3}{5} + \\frac{2}{5} \\log_2 \\frac{2}{5} \\right) \\approx 0.971<br>$$</p>\n<p>第二步：确定候选划分点集合</p>\n<p>根据公式 $T_a &#x3D; \\left{ \\frac{a^i + a^{i+1}}{2} ,\\middle|, 1 \\leq i \\leq n - 1 \\right}$，我们得到候选划分点集合：</p>\n<p>$$<br>T_a &#x3D; {2, 4, 6, 8}<br>$$</p>\n<p>第三步：计算每个候选划分点的信息增益</p>\n<p>以划分点 $t &#x3D; 4$ 为例：</p>\n<ul>\n<li>$D_t^{-} &#x3D; {1, 3}$，类别为 ${0, 1}$</li>\n<li>$D_t^{+} &#x3D; {5, 7, 9}$，类别为 ${0, 1, 0}$</li>\n</ul>\n<p>计算这两个子集的熵：</p>\n<ul>\n<li>$$Ent(D_t^{-}) &#x3D; -\\left( \\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2} \\right) &#x3D; 1$$</li>\n<li>$$Ent(D_t^{+}) &#x3D; -\\left( \\frac{2}{3} \\log_2 \\frac{2}{3} + \\frac{1}{3} \\log_2 \\frac{1}{3} \\right) \\approx 0.918$$</li>\n</ul>\n<p>计算信息增益：</p>\n<p>$$<br>Gain(D, a, t&#x3D;4) &#x3D; Ent(D) - \\left( \\frac{|D_t^{-}|}{|D|} \\cdot Ent(D_t^{-}) + \\frac{|D_t^{+}|}{|D|} \\cdot Ent(D_t^{+}) \\right)<br>$$</p>\n<p>代入数值：</p>\n<p>$$<br>Gain(D, a, t&#x3D;4) &#x3D; 0.971 - \\left( \\frac{2}{5} \\cdot 1 + \\frac{3}{5} \\cdot 0.918 \\right) \\approx 0.029<br>$$</p>\n<p>重复上述过程，对所有划分点 $t &#x3D; 2, 4, 6, 8$ 进行类似计算，并选择使 $Gain(D, a, t)$ 最大的那个作为最优划分点。<br>;;;<br>+++</p>\n<h1 id=\"线性区别分析-LDA-FDA\"><a href=\"#线性区别分析-LDA-FDA\" class=\"headerlink\" title=\"线性区别分析 (LDA&#x2F;FDA)\"></a>线性区别分析 (LDA&#x2F;FDA)</h1><p>线性判别分析(linear discriminant analysis， LDA)是一种基于监督学习的降维方法，也称为Fisher线性判别分析(fisher’s discriminant analysis，FDA),对于一组具有标签信息的高维数据样本，LDA利用其类别信息，将其线性投影到一个低维空间上，在低维空间中同一类别样本尽可能靠近，不同类别样本尽可能彼此远离。</p>\n<ol>\n<li>计算数据样本集中每个类别样本的均值</li>\n<li>计算类内散度矩阵$S_w$和类间散度矩阵$S_b$</li>\n<li>根据$S_w^{-1}S_bW&#x3D;\\lambda W$来求解$S_w^{-1}S_b$所对应前$r$个最大特征值所对应特征向量$(w_1,w_2,…,w_r)$，构成矩阵W</li>\n<li>通过矩阵$W$将每个样本映射到低维空间，实现特征降维。</li>\n</ol>\n<p>具体不想看，考到就给了</p>\n<h1 id=\"Ada-Boosting\"><a href=\"#Ada-Boosting\" class=\"headerlink\" title=\"Ada Boosting\"></a>Ada Boosting</h1><p>。。看不懂懒得看</p>\n<h1 id=\"支持向量机\"><a href=\"#支持向量机\" class=\"headerlink\" title=\"支持向量机\"></a>支持向量机</h1><h1 id=\"生成学习模型\"><a href=\"#生成学习模型\" class=\"headerlink\" title=\"生成学习模型\"></a>生成学习模型</h1>",
            "tags": [
                "人工智能"
            ]
        },
        {
            "id": "http://example.com/2025/06/11/AI/week4-5/",
            "url": "http://example.com/2025/06/11/AI/week4-5/",
            "title": "Week4-5",
            "date_published": "2025-06-10T16:00:00.000Z",
            "content_html": "<p>#Ch3 搜索算法</p>\n<h2 id=\"无信息搜索\"><a href=\"#无信息搜索\" class=\"headerlink\" title=\"无信息搜索\"></a>无信息搜索</h2><p>BFS DFS 略</p>\n<h2 id=\"启发式搜索\"><a href=\"#启发式搜索\" class=\"headerlink\" title=\"启发式搜索\"></a>启发式搜索</h2><ul>\n<li>贪婪优先搜索<ul>\n<li>每次取最短的；缺点：不一定是最优的</li>\n<li>时间和空间复杂度均为 $O(b_m)$，b是搜索树分支因子，m是最大深度<br><img data-src=\"/figure1.png\"><br>:::info<br>每次取当前节点的下一个节点到终点中直线距离最短的<br>:::</li>\n</ul>\n</li>\n<li>A*算法<ul>\n<li>评价函数：f(n) &#x3D; g(n) + h(n)</li>\n<li>代价函数 g(n) 表示从起始结点到结点n的开销代价值</li>\n<li>启发函数 h(n) 表示从结点n到目标结点路径中所估算的最小开销代价值。</li>\n<li>评价函数 f(n) 可视为经过结点n、具有最小开销代价值的路径。<ul>\n<li>在最短路径问题中，g(?)为当前选择的路径的实际距离，即从上一个节点到下一个节点的实际距离，?(?)为下一个节点到目标城市的直线距离。每一次搜索，下一个节点选择与此刻城市连接的所有节点中，g(?)+?(?)最小的城市节点。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>:::info<br>取（当前节点到下一节点的距离+下一节点到目标城市的距离）最短的<br>:::<br>A*算法的完备性和最优性取决于搜索问题和启发函数的性质<br>一个良好的启发函数需要满足:可容性（admissible）;一致性（consistency）<br>如果启发函数是可容的，那么树搜索的A*算法满足最优性(最优性:搜索算法是否能保证找到的第一个解是最优解)<br>满足一致性条件的启发函数一定满足可容性条件，反之不一定</p>\n<h2 id=\"对抗搜索\"><a href=\"#对抗搜索\" class=\"headerlink\" title=\"对抗搜索\"></a>对抗搜索</h2><ul>\n<li><p>最小最大搜索（minimax）</p>\n<ul>\n<li>最小最大搜索是一个在你和对手轮流行动的情况下，为你自己寻找最优策略的算法。</li>\n<li>算法：略</li>\n<li>时间复杂度：$O(b^m)$</li>\n<li>空间复杂度：$O(bm)$</li>\n</ul>\n</li>\n<li><p>\\alpha-\\beta剪枝</p>\n<ul>\n<li>Minimax 会穷举整个博弈树，但我们可以用剪枝技巧跳过一些无用分支，让它跑得更快</li>\n<li>max层的下界取下一层（上界）里面最大的；min层的上界取下一层（下界）里面最小的<br>懒得写直接看例子：<br><img data-src=\"/figure2.png\"><br> Alpha-Beta 剪枝算法什么时候扩展的结点数量最少？</li>\n<li>每一层最左端结点的所有孩子结点均被访问，其他节点仅有最左端孩子结点被访问、其他孩子结点被剪枝。<br> 如果一个节点导致了其兄弟节点被剪枝，可知其孩子节点必然被扩展。</li>\n<li>最优效率下时间复杂度：$O(b^{m&#x2F;2})$  (或者m+1);最差的就是完全没剪枝和minimax一样</li>\n</ul>\n</li>\n<li><p>蒙特卡洛树搜索</p>\n<ul>\n<li>选择(UCB)、扩展(随机)、模拟(随机)、反向传播</li>\n<li>悔值函数<br>:::info<br>没完全懂，后面再回来研究<br>:::</li>\n</ul>\n</li>\n</ul>\n",
            "tags": [
                "人工智能"
            ]
        },
        {
            "id": "http://example.com/2025/05/20/AI/week1/",
            "url": "http://example.com/2025/05/20/AI/week1/",
            "title": "Week1",
            "date_published": "2025-05-19T16:00:00.000Z",
            "content_html": "<blockquote>\n<p>2025-2026春夏人工智能课程笔记</p>\n</blockquote>\n<h1 id=\"Ch1-绪论\"><a href=\"#Ch1-绪论\" class=\"headerlink\" title=\"Ch1 绪论\"></a>Ch1 绪论</h1><ul>\n<li>人工智能求解：<ul>\n<li>以符号主义为核心的逻辑推理：将概念（如命题等）符号化，从若干判断（前提）出发得到新判断（结论）</li>\n<li>以问题求解为核心的探寻搜索:探寻搜索依据已有信息来寻找满足约束条件的待求解问题的答案</li>\n<li>以数据驱动为核心的机器学习:从数据中发现数据所承载语义（如概念）的内在模式</li>\n<li>以行为主义为核心的强化学习:根据环境所提供的奖罚反馈来学习所处状态可施加的最佳行动，在“探索（未知空间）-利用（已有经验）（exploration vs. exploitation）”之间寻找平衡，完成某个序列化任务，具备自我学习能力</li>\n<li>以博弈对抗为核心的群体智能:从“数据拟合”优化解的求取向“均衡解”的求取迈进</li>\n</ul>\n</li>\n</ul>\n",
            "tags": [
                "人工智能"
            ]
        },
        {
            "id": "http://example.com/2025/05/20/AI/week2-3/",
            "url": "http://example.com/2025/05/20/AI/week2-3/",
            "title": "Week2-3",
            "date_published": "2025-05-19T16:00:00.000Z",
            "content_html": "<h1 id=\"Ch2-知识表达与推理\"><a href=\"#Ch2-知识表达与推理\" class=\"headerlink\" title=\"Ch2 知识表达与推理\"></a>Ch2 知识表达与推理</h1><h2 id=\"命题逻辑\"><a href=\"#命题逻辑\" class=\"headerlink\" title=\"命题逻辑\"></a>命题逻辑</h2><p><img data-src=\"/img1.png\"><br>真值表：<br><img data-src=\"/img2.png\"></p>\n<blockquote>\n<p>“条件”命题联结词中前提为假时命题结论永远为真，bi-conditional只有两个都是true或者都是false才是true<br>逻辑等价：给定命题p和命题q，如果&#x3D;&#x3D;p和q在所有情况下都具有同样真假结果&#x3D;&#x3D;，那么p和q在逻辑上等价，一般用 $\\equiv$ 来表示，即p $\\equiv$ q。<br>判断逻辑等价：画真值表<br>逻辑等价式：<br><img data-src=\"/img3.jpg\"><br><img data-src=\"/img4.png\"></p>\n</blockquote>\n<ul>\n<li>normal form<ul>\n<li>有限个简单合取式构成的析取式称为析取(or)范式</li>\n<li>由有限个简单析取式构成的合取式称为合取(and)范式</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"谓词逻辑\"><a href=\"#谓词逻辑\" class=\"headerlink\" title=\"谓词逻辑\"></a>谓词逻辑</h2><ul>\n<li>全称量词与存在量词</li>\n<li>约束变元、自由变元<br>:::info<br>在约束变元相同的情况下，量词的运算满足分配律：全称量词对析取没有分配律、存在量词对合取没有分配律<br>:::<br>$$\\begin{aligned}<br>(\\forall x)(A(x) \\lor B(x)) \\equiv (\\forall x)A(x) \\lor (\\forall x)B(x) 不成立<br>\\end{aligned}$$</li>\n</ul>\n<p>$$\\begin{aligned}<br>(\\forall x)(A(x) \\land B(x)) \\equiv (\\forall x)A(x) \\land (\\forall x)B(x) 成立<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\exists x)(A(x) \\lor B(x)) \\equiv (\\exists x)A(x) \\lor (\\exists x)B(x) 成立<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\exists x)(A(x) \\land B(x)) \\equiv (\\exists x)A(x) \\land (\\exists x)B(x) 不成立<br>\\end{aligned}$$<br>:::info<br>当公式中存在多个量词时，若多个量词都是全称量词或者都是存在量词，则量词的位置可以互换；若多个量词中既有全称量词又有存在量词，则量词的位置不可以随意互换<br>:::<br>$$\\begin{aligned}<br>(\\forall x)(\\forall y)A(x, y) \\equiv (\\forall y)(\\forall x)A(x, y)<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\exists x)(\\exists y)A(x, y) \\equiv (\\exists y)(\\exists x)A(x, y)<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\forall x)(\\forall y)A(x, y) \\equiv (\\exists y)(\\forall x)A(x, y)<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\forall x)(\\forall y)A(x, y) \\equiv (\\exists x)(\\forall y)A(x, y)<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\exists y)(\\forall x)A(x, y) \\equiv (\\forall x)(\\exists y)A(x, y)<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\exists x)(\\forall y)A(x, y) \\equiv (\\forall y)(\\exists x)A(x, y)<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\forall x)(\\exists y)A(x, y) \\equiv (\\exists y)(\\exists x)A(x, y)<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>(\\forall y)(\\exists x)A(x, y) \\equiv (\\exists x)(\\exists y)A(x, y)<br>\\end{aligned}$$</p>\n<ul>\n<li>利用谓词逻辑进行推理<ul>\n<li>全称量词消去： $(\\forall x) A(x) \\equiv A(y)$</li>\n<li>全称量词引入： $A(y) \\equiv (\\forall x) A(x)$</li>\n<li>存在量词消去： $(\\exists x) A(x) \\equiv A(c)$</li>\n<li>存在量词引入： $A(c) \\equiv (\\exists x) A(x)$</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"知识图谱推理\"><a href=\"#知识图谱推理\" class=\"headerlink\" title=\"知识图谱推理\"></a>知识图谱推理</h2><ul>\n<li>知识图谱可视为包含多种关系的图。在图中，每个节点是一个实体（如人名、地名、事件和活动等），任意两个节点之间的边表示这两个节点之间存在的关系。</li>\n<li>可将知识图谱中任意两个相连节点及其连接边表示成一个三元组（triplet）,即 (left_node, relation, right_node)<br>两类代表性方法：</li>\n<li>归纳逻辑程序设计 (inductive logic programming，ILP)算法</li>\n<li>路径排序算法（path ranking algorithm, PRA）</li>\n</ul>\n<p>ILP: 一阶归纳学习FOIL（First Order Inductive Learner）<br>推理手段: 正例集合 + 反例集合 + 背景知识样例 ⟹ 目标谓词作为结论的推理规则<br><img data-src=\"/img5.png\"><br>懒得写了，看ppt吧<br><img data-src=\"/img6.png\"><br>推理规则覆盖所有正例且不覆盖任何反例的时候算法结束</p>\n<p>PRA: 路径排序算法<br><img data-src=\"/img7.png\"><br>(4)的意思是看两个实体能不能通过(3)的关系从第一个走到第二个。<br>后面的1表示正例，-1表示负例。</p>\n<h2 id=\"概率图推理\"><a href=\"#概率图推理\" class=\"headerlink\" title=\"概率图推理\"></a>概率图推理</h2><p>贝叶斯网络<br>马尔科夫逻辑网络</p>\n<h2 id=\"因果推理\"><a href=\"#因果推理\" class=\"headerlink\" title=\"因果推理\"></a>因果推理</h2><p>因果定义：变量X是变量Y的原因，当且仅当保持其它所有变量不变的情况下，改变X的值能导致Y的值发生变化。<br>因果效应：因变量X改变一个单位时，果变量Y的变化程度</p>\n<p>因果图是有向无环图</p>\n<p>结构因果模型：结构因果模型由两组变量集合U和V以及一组函数f组成。其中，f是根据模型中其他变量取值而给V中每一个变量赋值的函数<br>结构因果模型中的原因：如果变量X出现在给变量X赋值的函数中，如$Y &#x3D; f(X) + \\epsilon$，则X是Y的直接原因<br>因果图中的联合概率分布：直接看图<br><img data-src=\"/img8.png\"><br>因果图的基本结构：</p>\n<ul>\n<li>链结构<br>  - <img data-src=\"/img9.png\"><br>  - 对于变量X和Y，若X和Y之间只有一条单向的路径，变量Z是截断(intercept)该路径的集合中的任一变量，则在给定Z时，X和Y条件独立。</li>\n</ul>\n<p>$$<br>P(X, Y | Z) &#x3D; P(X | Z)P(Y | Z)<br>$$</p>\n<ul>\n<li>分连结构<br>  - <img data-src=\"/img10.png\"></li>\n</ul>\n<p>$$<br>P(X, Y | Z) &#x3D; \\frac {P(X, Y, Z)}{P(Z)} &#x3D; \\frac {P(X | Z)P(Y | Z)P(Z)}{P(Z)} &#x3D; P(X | Z)P(Y | Z)<br>$$</p>\n<ul>\n<li>汇联结构<br>  - <img data-src=\"/img11.png\"></li>\n</ul>\n<p>$$<br>P(X, Y | Z) &#x3D; \\frac{P(X, Y, Z)} {P(Z)} &#x3D; \\frac {P(X, Y, Z)}{P(Z)} &#x3D; \\frac {P(X)P(Y)P(Z&#x2F;X, Y)}{P(Z)} \\neq P(X | Z)P(Y | Z)<br>$$</p>\n<h3 id=\"D-分离-directional-separation-d-separation-，可用于判断任意两个节点的相关性和独立性\"><a href=\"#D-分离-directional-separation-d-separation-，可用于判断任意两个节点的相关性和独立性\" class=\"headerlink\" title=\"D-分离(directional separation, d-separation)，可用于判断任意两个节点的相关性和独立性\"></a>D-分离(directional separation, d-separation)，可用于判断任意两个节点的相关性和独立性</h3><ul>\n<li>限定集：已知或观察到的变量集合（给定的变量集合）</li>\n<li>路径p被限定集Z阻塞(block)当且仅当：<ul>\n<li>(1) 路径p含有链结构A → B → C或分连结构A ← B → C且中间节点B在Z中，或</li>\n<li>(2) 路径p含有汇连结构A → B ← C且汇连节点B及其后代都不在Z中。</li>\n<li>若Z阻塞了节点X和节点Y之间的每一条路径，则称给定Z时，X和Y是D-分离，即给定Z时，X和Y条件独立</li>\n<li>&#x3D;&#x3D;链式、分连中间节点在，汇联中间节点和后代不在则D-分离&#x3D;&#x3D;</li>\n</ul>\n</li>\n</ul>\n<p>因果定义：变量X是变量Y的原因，当且仅当保持其它所有变量不变的情况下，改变X的值能导致Y的值发生变化。<br>因果效应：因变量X改变一个单位时，果变量Y的变化程度因果推理的两个关键因素：</p>\n<ul>\n<li>改变因变量T</li>\n<li>保证其它变量不变<br>干预：干预(intervention)指的是固定(fix)系统中的变量，然后改变系统，观察其他变量的变化。<br>为了与X自然取值x时进行区分，在对X进行干预时，引入“do算子”(do-calculus)，记作do(X &#x3D; x)。<br>因此，P(Y &#x3D; y|X &#x3D; x)表示的是当发现X &#x3D; x时，Y&#x3D; y的概率；而P(Y &#x3D; y|do(X &#x3D;x))表示的是对X进行干预，固定其值为x时，Y &#x3D; y的概率。<br>用统计学的术语来说，P(Y &#x3D; y|X &#x3D; x)反映的是在取值为x的个体X上，Y的总体分布；而P(Y &#x3D; y|do(X &#x3D;x))反映的是如果将每一个X取值都固定为x时，Y的总体分布。</li>\n</ul>\n<p>因果效应差&#x2F;平均因果效应 (ACE)  懒得写了看图吧<br><img data-src=\"/img12.png\"><br><img data-src=\"/img13.png\"><br>计算因果效应的关键在于计算操纵概率(manipulatedprobability) $P_m$<br>调整公式：<br>$$<br>P(Y &#x3D; y \\mid do(X &#x3D; x)) &#x3D; \\sum_z P(Y &#x3D; y \\mid X &#x3D; x, Z &#x3D; z) \\cdot P(Z &#x3D; z)<br>$$<br>对于Z的每一个取值z，计算X和Y的条件概率并取均值<br>+++info example<br>;;;id3 例题<br>假设我们研究以下变量：</p>\n<ul>\n<li>X：是否服药  <ul>\n<li>$X &#x3D; 1$：服药  </li>\n<li>$X &#x3D; 0$：不服药</li>\n</ul>\n</li>\n<li>Y：是否康复  <ul>\n<li>$Y &#x3D; 1$：康复  </li>\n<li>$Y &#x3D; 0$：未康复</li>\n</ul>\n</li>\n<li>Z：性别  <ul>\n<li>$Z &#x3D; 0$：男  </li>\n<li>$Z &#x3D; 1$：女<br>我们知道性别会影响：</li>\n</ul>\n</li>\n<li>是否选择服药（比如男性更倾向于尝试新药）</li>\n<li>康复率（比如女性可能有更强的免疫力）<br>因此，性别 Z 是一个混杂变量，需要在分析中进行控制。<br>已知：<table>\n<thead>\n<tr>\n<th>Z（性别）</th>\n<th>P(Z)</th>\n<th>P(Y&#x3D;1 | X&#x3D;1, Z)</th>\n<th>P(Y&#x3D;1 | X&#x3D;0, Z)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>男（0）</td>\n<td>0.6</td>\n<td>0.7</td>\n<td>0.4</td>\n</tr>\n<tr>\n<td>女（1）</td>\n<td>0.4</td>\n<td>0.5</td>\n<td>0.3</td>\n</tr>\n<tr>\n<td>我们想知道：</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>如果强制所有人都服药（即 $do(X&#x3D;1)$），整体康复率是多少？</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>也就是要计算：</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>$$</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>P(Y&#x3D;1 \\mid do(X&#x3D;1))</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>$$</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>;;;</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>;;;id3 答案</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>根据调整公式：</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<p>$$<br>P(Y&#x3D;1 \\mid do(X&#x3D;1)) &#x3D; \\sum_z P(Y&#x3D;1 \\mid X&#x3D;1, Z&#x3D;z) \\cdot P(Z&#x3D;z)<br>$$</p>\n<p>代入数据计算</p>\n<p>$$<br>P(Y&#x3D;1 \\mid do(X&#x3D;1)) &#x3D; P(Y&#x3D;1 \\mid X&#x3D;1, Z&#x3D;0) \\cdot P(Z&#x3D;0) + P(Y&#x3D;1 \\mid X&#x3D;1, Z&#x3D;1) \\cdot P(Z&#x3D;1)<br>$$</p>\n<p>$$<br>&#x3D; 0.7 \\times 0.6 + 0.5 \\times 0.4 &#x3D; 0.42 + 0.2 &#x3D; 0.62<br>$$<br>+++</p>\n<p>(因果效应)给定因果图G，PA表示X的父节点集合，则X对Y的因果效应为<br>$$<br>P(Y&#x3D;y \\mid do(X&#x3D;x)) &#x3D; \\sum_z P(Y&#x3D;y \\mid X&#x3D;x, PA&#x3D;z) \\cdot P(PA&#x3D;z)<br>$$<br>后门调整：<br>不写了</p>\n",
            "tags": [
                "人工智能"
            ]
        },
        {
            "id": "http://example.com/2025/05/14/computer-science/computer-organization/ch2/",
            "url": "http://example.com/2025/05/14/computer-science/computer-organization/ch2/",
            "title": "Ch2",
            "date_published": "2025-05-13T16:00:00.000Z",
            "content_html": "<h1 id=\"Ch2-数据的表示和运算\"><a href=\"#Ch2-数据的表示和运算\" class=\"headerlink\" title=\"Ch2 数据的表示和运算\"></a>Ch2 数据的表示和运算</h1><h2 id=\"2-1-进位计数制及其相互转换\"><a href=\"#2-1-进位计数制及其相互转换\" class=\"headerlink\" title=\"2.1 进位计数制及其相互转换\"></a>2.1 进位计数制及其相互转换</h2><h3 id=\"2-1-1\"><a href=\"#2-1-1\" class=\"headerlink\" title=\"2.1.1\"></a>2.1.1</h3><ul>\n<li>十进制二进制八进制十六进制转换<ul>\n<li>略</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-1-2-定点数的编码表示\"><a href=\"#2-1-2-定点数的编码表示\" class=\"headerlink\" title=\"2.1.2 定点数的编码表示\"></a>2.1.2 定点数的编码表示</h3><ul>\n<li>定点百世一般表示定点小数和定点整数，小数是符号位.xxx，整数是符号位xxxx.0</li>\n<li><blockquote>\n<p>感觉不是什么重要的东西，浮点数表示比较重要</p>\n</blockquote>\n</li>\n<li>原码，反码，补码<ul>\n<li>正数的原码反码补码相同</li>\n<li>原码表示的范围为 $-2^n+1 ~ 2^n-1$</li>\n<li>补码表示的范围为 $-2^n ~ 2^n-1$</li>\n<li>负数的原码是1+绝对值，反码是1+绝对值取反，补码是反码+1</li>\n</ul>\n</li>\n<li>移码：用来表示浮点数的阶码，只能表示整数<ul>\n<li>一般用移码表示浮点数的阶码，用补码表示定点整数<br>$$ [x]_移 &#x3D; 2^n + x $$<br>移码就是在真值x前面加一个offset，比如取offset为2^7，就在补码的第8位加上1</li>\n<li>比如正数10101，移码是10010101，负数-10101的补码是11101011，所以移码是01101011</li>\n<li>移码的作用是&#x3D;&#x3D;保持数据原有的大小顺序&#x3D;&#x3D;，移码大真值大，移码小真值小，所以可以直观地进行比较<br>:::warning<br>相同位数的补码和移码表示具有相同的数据表示范围，区别只是表示方法不同<br>补码与移码只差一个符号位。同一个数的补码和移码表示，其数值部分相同，而符号位相反。<br>:::</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-1-3-整数表示\"><a href=\"#2-1-3-整数表示\" class=\"headerlink\" title=\"2.1.3 整数表示\"></a>2.1.3 整数表示</h3><p>略</p>\n<h3 id=\"2-1-4\"><a href=\"#2-1-4\" class=\"headerlink\" title=\"2.1.4\"></a>2.1.4</h3><p>c中的强制转换<br>short转成unsigned short直接把二进制看成unsigned short，比如-1变成65535<br>int变成short直接截断<br>小字长转大字长不会改变值，如果是unsigned就会在前面补0，如果是有符号数就在前面补符号位<br>short转unsigned int，先对short进行符号扩展到int，再把它当做unsigned int，如果是unsigned short转int，就进行零扩展再看成int……</p>\n<p>一些题目<br>+++info example<br>;;;id3 t1<br>若$[x]_补 &#x3D; 1,x_1x_2x_3x_4x_5x_6$,其中$x_i$取0或1，若要x&gt;-32，应当满足：<br>C. $x_1$为1，$x_2…x_6$中至少有一位为1<br>1100000是-32，要比-32大所以绝对值要小，所以数值部分要大，所以$x_1$必须是1,后面随便有个1就行<br>;;;<br>;;;id3 t2<br>设x为正数，$[x]_补 &#x3D; 1,x_1x_2x_3x_4x_5$,若要x&lt;-16，应当满足：<br>C. $x_1$必须为0，其它任意<br>110000是-16，要小于-16所以数值部分绝对值要小，所以只要$x_1$为0就比-16小<br>;;;<br>;;;id3 t3<br>一个8位的二进制整数由2个“0”和6个“1”组成，采用补码或者移码表示，则<br>若采用移码表示，偏置值为127，则此整数最小为-64（偏置为127需要在补码加上1111111，&#x3D;&#x3D;要让数值最小，应该把1放低位&#x3D;&#x3D;，所以移码是00111111，补码是10111111是-64）</p>\n<blockquote>\n<p>：前面说过，移码大真值大，移码小真值小，所以要让数值最小把1放低位就行了</p>\n</blockquote>\n<p>若采用补码表示，则此整数最小为-97（10011111&#x3D;-97）<br>;;;<br>;;;id3 比较大小的方法<br>对于无符号数，数值大的数就大<br>对于有符号数的原码和反码比较大小：先看正负然后看数值，反码数值转成原码再比<br>对于补码比较大小，正数正常比较，负数数值部分越小，绝对值越大（前面1更多的数的绝对值越小，所以11111111是-1）<br>;;;<br>+++</p>\n<h2 id=\"2-2-运算方法和运算电路\"><a href=\"#2-2-运算方法和运算电路\" class=\"headerlink\" title=\"2.2 运算方法和运算电路\"></a>2.2 运算方法和运算电路</h2><h3 id=\"2-2-1-基本运算部件\"><a href=\"#2-2-1-基本运算部件\" class=\"headerlink\" title=\"2.2.1 基本运算部件\"></a>2.2.1 基本运算部件</h3><h4 id=\"一位全加器\"><a href=\"#一位全加器\" class=\"headerlink\" title=\"一位全加器\"></a>一位全加器</h4><ul>\n<li>用真值表实现的：进位C，和S<table>\n<thead>\n<tr>\n<th align=\"center\">A</th>\n<th align=\"center\">B</th>\n<th align=\"center\">Cin</th>\n<th align=\"center\">Cout</th>\n<th align=\"center\">S</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<ul>\n<li>可以用卡诺图或者直接理解(王道不写还好我本来就会，差点忘了。。。)<br><img data-src=\"/img2.jpg\"><br>$$<br>\\begin{aligned}<br>S &amp;&#x3D; \\overline{A} , \\overline{B} , C_i + \\overline{A} , B , \\overline{C_i} + A , \\overline{B} , \\overline{C_i} + A , B , C_i \\<br>&amp;&#x3D; A \\oplus B \\oplus C_i<br>\\end{aligned}<br>$$<br>$$<br>\\begin{aligned}<br>Co &amp;&#x3D; AB + A \\overline{B} C_i + \\overline{A} B C_i \\<br>&amp;&#x3D; AB + (A \\oplus B) \\cdot C_i<br>\\end{aligned}<br>$$</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"串行进位加法器\"><a href=\"#串行进位加法器\" class=\"headerlink\" title=\"串行进位加法器\"></a>串行进位加法器</h4><ul>\n<li>把n个一位全加器连起来<br><img data-src=\"/img3.png\"><br>Carry Propagation &amp; Delay</li>\n</ul>\n<h4 id=\"并行进位加法器\"><a href=\"#并行进位加法器\" class=\"headerlink\" title=\"并行进位加法器\"></a>并行进位加法器</h4><p>对Cin进行look ahead</p>\n<p><img data-src=\"/img4.png\"></p>\n<p>前面提到：<br>$$<br>\\begin{aligned}<br>Co &amp;&#x3D; AB + A \\overline{B} C_i + \\overline{A} B C_i \\<br>   &amp;&#x3D; AB + (A \\oplus B) \\cdot C_i<br>\\end{aligned}<br>$$<br>下一位的Cin等于上一位的Cout，所以可以进行look ahead，这里让<br>$$<br>\\begin{aligned}<br>G_i &amp;&#x3D; A_iB_i<br>\\end{aligned}<br>$$<br>$$<br>\\begin{aligned}<br>P_i &amp;&#x3D; A_i \\oplus B_i<br>\\end{aligned}<br>$$<br>所以<br>$$<br>\\begin{aligned}<br>C_{i+1} &amp;&#x3D; G_i + P_iC_i<br>\\end{aligned}<br>$$<br>$$<br>\\begin{aligned}<br>S_i &amp;&#x3D; P_i \\oplus C_i<br>\\end{aligned}<br>$$<br>就能得到超前进位的效果</p>\n<h4 id=\"带标志加法器\"><a href=\"#带标志加法器\" class=\"headerlink\" title=\"带标志加法器\"></a>带标志加法器</h4><p><img data-src=\"/img5.jpg\"></p>\n<ul>\n<li>溢出标志 $OF &#x3D; C_n  \\oplus C_{n-1}$，只能判断有符号数是否溢出<br>-两个正数加起来变成负数或者两个负数加起来变成正数，就会溢出<table>\n<thead>\n<tr>\n<th align=\"center\">A</th>\n<th align=\"center\">B</th>\n<th align=\"center\">$C_{n-1}$</th>\n<th align=\"center\">F</th>\n<th align=\"center\">$C_n$</th>\n<th align=\"center\">OF</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<blockquote>\n<p>第二行A&#x3D;0, B&#x3D;0, F&#x3D;1，正+正&#x3D;负<br>  第七行A&#x3D;0, B&#x3D;1, F&#x3D;0，负+负&#x3D;正<br>  所以OF&#x3D;1，表示有溢出<br>  观察发现$OF &#x3D; C_{n-1}  \\oplus C_n$</p>\n</blockquote>\n<ul>\n<li>符号标志 $SF &#x3D; F_{n-1}$，输出的最高位决定有符号数的正负</li>\n<li>进位&#x2F;借位标志：用于判断无符号数的加减运算是否溢出<ul>\n<li>$CF &#x3D; Cin \\oplus Cout$</li>\n<li>此处的Cin和Cout表示最开始的输入和最后的输出，还没理解</li>\n</ul>\n</li>\n<li>零标志 当且仅当所有F&#x3D;0时为1，否则为0（把所有F作或非）</li>\n</ul>\n<h4 id=\"ALU\"><a href=\"#ALU\" class=\"headerlink\" title=\"ALU\"></a>ALU</h4><p>略</p>\n<h3 id=\"2-2-2-定点数的移位运算\"><a href=\"#2-2-2-定点数的移位运算\" class=\"headerlink\" title=\"2.2.2 定点数的移位运算\"></a>2.2.2 定点数的移位运算</h3><ul>\n<li>左移一位*2，右移一位&#x2F;2</li>\n<li>逻辑移位：移完直接补0<ul>\n<li>无符号数若高位的1移出，则发生溢出</li>\n</ul>\n</li>\n<li>算数移位：有符号数右移时，补符号位，左移如果高位和符号位不同，则发生溢出</li>\n</ul>\n<h3 id=\"定点数的加减运算\"><a href=\"#定点数的加减运算\" class=\"headerlink\" title=\"定点数的加减运算\"></a>定点数的加减运算</h3><p>补码相加减，略<br>主要是溢出判断：符号相同的数相加或者符号相异的数相减会发生溢出</p>\n<ul>\n<li>一位符号位（参考前面OF）</li>\n<li>双符号位（模4补码）<ul>\n<li>符号位左边那一位表示正确的符号，0为正，1为负；右边那一位如果和左边的相同，如 “00”表示正且无溢出，”11”表示负且无溢出。如果右边那一位与左边那一位不一样，则表示有溢出</li>\n<li>溢出逻辑判断：若V为0则无溢出，V为1则溢出<br>$$<br>V &#x3D; S_{s1} \\oplus S_{s2}<br>$$<br>例子看这篇写的挺清楚：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1bl9ib3lfYm95X3N1bi9hcnRpY2xlL2RldGFpbHMvODc5MTcwMjA=\">https://blog.csdn.net/sun_boy_boy_sun/article/details/87917020</span><br>总之两位不同则有溢出</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"定点数的乘除运算\"><a href=\"#定点数的乘除运算\" class=\"headerlink\" title=\"定点数的乘除运算\"></a>定点数的乘除运算</h3><p>略，列竖式即可</p>\n",
            "tags": [
                "数据的表示与运算"
            ]
        },
        {
            "id": "http://example.com/2025/05/13/computer-science/computer-organization/ch1/",
            "url": "http://example.com/2025/05/13/computer-science/computer-organization/ch1/",
            "title": "Ch1",
            "date_published": "2025-05-12T16:00:00.000Z",
            "content_html": "<blockquote>\n<p>王道计组考研复习笔记<br>怕学完忘了写个笔记保留一下顺便加深印象x<br>王道书写得好烂、、</p>\n</blockquote>\n<h1 id=\"Ch1-计算机系统概述\"><a href=\"#Ch1-计算机系统概述\" class=\"headerlink\" title=\"Ch1 计算机系统概述\"></a>Ch1 计算机系统概述</h1><h2 id=\"1-1-计算机发展历程\"><a href=\"#1-1-计算机发展历程\" class=\"headerlink\" title=\"1.1 计算机发展历程\"></a>1.1 计算机发展历程</h2><ul>\n<li>四代计算机：电子管-&gt;晶体管-&gt;集成电路-&gt;超大规模集成电路</li>\n<li>摩尔定律：集成电路上可以容纳的晶体管数目在大约每经过18个月到24个月便会增加一倍</li>\n</ul>\n<h2 id=\"1-2-计算机系统层次结构\"><a href=\"#1-2-计算机系统层次结构\" class=\"headerlink\" title=\"1.2 计算机系统层次结构\"></a>1.2 计算机系统层次结构</h2><ul>\n<li>计算机系统：硬件+软件</li>\n<li>对于某一功能，既能用软件实现又能用硬件实现，称为软、硬件在逻辑功能上是等价的</li>\n</ul>\n<h3 id=\"1-2-2-硬件\"><a href=\"#1-2-2-硬件\" class=\"headerlink\" title=\"1.2.2 硬件\"></a>1.2.2 硬件</h3><ul>\n<li>冯·诺依曼机的特点：<ul>\n<li>采用“存储程序”的工作方式</li>\n<li>冯·诺依曼计算机由五大部件组成：运算器、控制器、存储器、输入设备和输出设备</li>\n<li>指令和数据以同等地位存储在存储器中</li>\n<li>指令和数据均用二进制代码表示</li>\n<li>指令由操作码和地址码组成</li>\n<li><img data-src=\"/img1.png\"></li>\n</ul>\n</li>\n<li>计算机的功能部件：<ul>\n<li>输入设备</li>\n<li>输出设备</li>\n<li>存储器：主存+外存<ul>\n<li>CPU能直接访问的是主存</li>\n<li><img data-src=\"/img2.jpg\"></li>\n<li>MAR位10位则最多有$2^{10}$个存储单元</li>\n<li>在现代计算机中MAR和MDR存在CPU中</li>\n</ul>\n</li>\n<li>运算器：进行算术运算和逻辑运算<ul>\n<li>核心是ALU：通用寄存器有&#x3D;&#x3D;累加器(ACC)，乘商寄存器(MQ)，操作数寄存器(X)&#x3D;&#x3D;，变址寄存器(IX)，基址寄存器(BR)等，前三个必备</li>\n<li>程序状态寄存器(PSW)</li>\n<li><img data-src=\"/img3.jpg\"></li>\n</ul>\n</li>\n<li>控制器：由PC, IR和control unit组成<ul>\n<li>: RISCV控制器</li>\n<li><img data-src=\"/img4.png\"></li>\n</ul>\n</li>\n<li>CPU由运算器、控制器和cache组成</li>\n<li>总线有地址总线、数据总线、控制总线</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-2-3-软件\"><a href=\"#1-2-3-软件\" class=\"headerlink\" title=\"1.2.3 软件\"></a>1.2.3 软件</h3><ul>\n<li>组成：系统软件(OS, DBMS, 编译器, …)+应用软件</li>\n<li>语言：汇编语言、机器语言、高级语言<ul>\n<li>汇编器：把汇编语言翻译成机器语言</li>\n<li>编译器：把高级语言翻译成汇编语言或机器语言</li>\n<li>解释器：把高级语言翻译成&#x3D;&#x3D;机器语言&#x3D;&#x3D;(比如python)<br>  +++info example<br>  ;;;id3 题目<br>  :chestnut:<br>  将高级语言源程序转换为机器级目标代码文件的程序是 []。<br>  A. 汇编程序<br>  B. 链接程序<br>  C. 编译程序<br>  D. 解释程序<br>  ;;;<br>  ;;;id3 答案<br>  C. 编译程序<br>  因为解释程序不生成目标代码，编译器可以把高级语言翻译成汇编语言或者直接翻译成机器语言<br>  ;;;<br>  +++</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-2-4-计算机系统的层次结构\"><a href=\"#1-2-4-计算机系统的层次结构\" class=\"headerlink\" title=\"1.2.4 计算机系统的层次结构\"></a>1.2.4 计算机系统的层次结构</h3><ul>\n<li>看看就好</li>\n<li><img data-src=\"/img5.png\"></li>\n</ul>\n<h3 id=\"1-2-5-计算机系统的工作原理\"><a href=\"#1-2-5-计算机系统的工作原理\" class=\"headerlink\" title=\"1.2.5 计算机系统的工作原理\"></a>1.2.5 计算机系统的工作原理</h3><ul>\n<li>程序执行前，需要把所含的指令和数据一起放入主存中</li>\n<li>五个阶段：IF-ID-EX-MEM-WB</li>\n<li>c程序怎么变成可执行文件的：直接看图<ul>\n<li><img data-src=\"/img6.png\"></li>\n<li>汇编器把指令打包成可重定位目标代码文件：使用相对地址和符号引用来表示各个代码段之间的关系（代码段、数据段、符号表、重定位表…）使得代码或数据能在内存中任意位置加载或运行</li>\n</ul>\n</li>\n<li>指令执行过程：后面几章会具体讲</li>\n</ul>\n<h2 id=\"1-3-计算机的性能指标\"><a href=\"#1-3-计算机的性能指标\" class=\"headerlink\" title=\"1.3 计算机的性能指标\"></a>1.3 计算机的性能指标</h2><h3 id=\"1-3-1-主要性能指标\"><a href=\"#1-3-1-主要性能指标\" class=\"headerlink\" title=\"1.3.1 主要性能指标\"></a>1.3.1 主要性能指标</h3><ul>\n<li>字长：一次整数运算所能处理的二进制数据的位数<br> :::info<br> 机器字长、指令字长和存储字长<br> :::</li>\n<li>带宽<code>bandwidth</code>：总线一次能并行传送信息的位数</li>\n<li>主存容量</li>\n<li>运算速度<ul>\n<li>吞吐量<code>throughput</code>：一次输入数据所对应的输出数据个数</li>\n<li>响应时间<code>Response (Execution) time</code></li>\n<li>主频</li>\n<li>clock cycle time( &#x3D; 1&#x2F;CPU frequency)</li>\n<li>MIPS: million instructions per second</li>\n<li>FLOPS: floating-point operations per second<blockquote>\n<p>CPI: clock cycles per instruction(IPC: CPI的倒数)</p>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<p>$$ \\begin{aligned}<br>    \\text{CPU execution time} &amp;&#x3D; \\text{CPU clock cycles} \\times \\text{Clock cycle time} \\<br>    &amp;&#x3D; \\frac{\\text{CPU clock cycles}}{\\text{Clock rate}}<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>    \\text{CPU clock cycles} &amp;&#x3D; \\text{Instructions count} \\times \\text{Average cycles per instruction}<br>\\end{aligned}$$</p>\n<p>$$\\begin{aligned}<br>    \\text{CPU execution time} &amp;&#x3D; \\text{CPU clock cycles} \\times \\text{Clock cycle time} \\<br>    &amp;&#x3D; \\frac{\\text{CPU clock cycles}}{\\text{Clock rate}}<br>\\end{aligned} $$</p>\n<p>$$ \\begin{aligned}<br>     \\text{performance} &amp;&#x3D; \\frac{1}{\\text{CPU execution time}}<br>\\end{aligned}$$</p>\n<p>“Processor X is n times fast than Y” is<br>$$ \\begin{aligned}<br>    \\text{n} &amp;&#x3D; \\frac{\\text{CPU execution time of Y}}{\\text{CPU execution time of X}}<br>\\end{aligned}$$</p>\n<p>IPS: instructions per second<br>$$ \\begin{aligned}<br>    \\text{IPS} &amp;&#x3D; \\frac{\\text{CPU frequency}}{\\text{CPI}}<br>        &amp;&#x3D; \\frac{1}{\\text{CPU clock cycles} \\times \\text{CPU execution time}}<br>\\end{aligned}$$</p>\n<ul>\n<li>其他公式，，，用到再说吧</li>\n<li>兼容：软件或硬件的通用性</li>\n</ul>\n<blockquote>\n<p>在用于科学计算的计算机中，标志系统性能最有用的参数是浮点数运算相关的</p>\n<ul>\n<li>MFLOPS 10^6</li>\n<li>GFLOPS 10^9</li>\n<li>TFLOPS 10^12</li>\n<li>PFLOPS 10^15</li>\n<li>EFLOPS 10^18</li>\n<li>ZFLOPS 10^21</li>\n</ul>\n</blockquote>\n",
            "tags": [
                "计算机组成"
            ]
        },
        {
            "id": "http://example.com/2025/05/13/computer-science/computer-network/ch1/",
            "url": "http://example.com/2025/05/13/computer-science/computer-network/ch1/",
            "title": "Ch1",
            "date_published": "2025-05-12T16:00:00.000Z",
            "content_html": "",
            "tags": [
                "计算机网络"
            ]
        },
        {
            "id": "http://example.com/2025/03/29/computer-science/compile-principles/ch4/",
            "url": "http://example.com/2025/03/29/computer-science/compile-principles/ch4/",
            "title": "Ch4",
            "date_published": "2025-03-28T16:00:00.000Z",
            "content_html": "",
            "tags": [
                "抽象语法"
            ]
        },
        {
            "id": "http://example.com/2025/03/23/computer-science/compile-principles/ch3/",
            "url": "http://example.com/2025/03/23/computer-science/compile-principles/ch3/",
            "title": "Ch3",
            "date_published": "2025-03-22T16:00:00.000Z",
            "content_html": "<h1 id=\"语法分析\"><a href=\"#语法分析\" class=\"headerlink\" title=\"语法分析\"></a>语法分析</h1><h2 id=\"CFG\"><a href=\"#CFG\" class=\"headerlink\" title=\"CFG\"></a>CFG</h2><p>见计算理论<br>Parse tree</p>\n<h3 id=\"Ambiguous-grammars\"><a href=\"#Ambiguous-grammars\" class=\"headerlink\" title=\"Ambiguous grammars\"></a>Ambiguous grammars</h3><h2 id><a href=\"#\" class=\"headerlink\" title></a></h2>",
            "tags": [
                "语法分析"
            ]
        },
        {
            "id": "http://example.com/2025/03/22/computer-science/compile-principles/ch2/",
            "url": "http://example.com/2025/03/22/computer-science/compile-principles/ch2/",
            "title": "Ch2",
            "date_published": "2025-03-21T16:00:00.000Z",
            "content_html": "<h1 id=\"Ch2-词法分析\"><a href=\"#Ch2-词法分析\" class=\"headerlink\" title=\"Ch2 词法分析\"></a>Ch2 词法分析</h1><blockquote>\n<p>把input分解成一个个token</p>\n</blockquote>\n<h2 id=\"Regular-Expression\"><a href=\"#Regular-Expression\" class=\"headerlink\" title=\"Regular Expression\"></a>Regular Expression</h2><ul>\n<li>Language: a set of strings</li>\n<li>String: a finite sequence of characters<blockquote>\n<p>Regular Experssion Notations:<br><img data-src=\"/image-1.png\"></p>\n</blockquote>\n</li>\n</ul>\n<p>:::info<br>DFA, NFA相关 见计算理论<br>:::</p>\n<h2 id=\"RE转NFA\"><a href=\"#RE转NFA\" class=\"headerlink\" title=\"RE转NFA\"></a>RE转NFA</h2><p>:::info 方法：</p>\n<ol>\n<li>画出初始态和终态</li>\n<li>分裂规则：<br><img data-src=\"/image-2.jpg\"><br>:::</li>\n</ol>\n<h2 id=\"NFA转DFA\"><a href=\"#NFA转DFA\" class=\"headerlink\" title=\"NFA转DFA\"></a>NFA转DFA</h2><p>从初始状态的闭包开始，每次根据\\epsilon和当前状态的闭包，得到下一个状态的闭包，直到得到终态的闭包。</p>\n<p>+++info example<br>;;;id3 题目<br>:chestnut:<br>把这个NFA转成等价的DFA<br><img data-src=\"/image-3.png\"><br>;;;<br>;;;id3 答案<br>初态的闭包是1、2、6，1、2、6经过a可以转移到3、7，因为有\\epsilon转移，所以3、7的闭包是3、4、7、8，同理3、4、7、8经过b可以到5、8，由于8是终态，把所有包含8的圆圈画成终态的环。<br><img data-src=\"/image-4.png\"><br>;;;<br>+++</p>\n<h2 id=\"最小化DFA\"><a href=\"#最小化DFA\" class=\"headerlink\" title=\"最小化DFA\"></a>最小化DFA</h2><p>含义：</p>\n<ol>\n<li>没有多余状态：</li>\n</ol>\n<ul>\n<li>从这个状态没有通路到达终态</li>\n<li>从开始状态出发，任何输入串也不能到达的那个状态</li>\n</ul>\n<ol start=\"2\">\n<li>没有两个状态相互等价<br>:::info 方法：</li>\n<li>多余状态直接删除<br><img data-src=\"/image-5.png\"></li>\n<li>合并等价状态</li>\n</ol>\n<ul>\n<li>将状态分为终态和非终态两个集合</li>\n<li>遍历每个集合，如果经过转换到达的状态都在当前集合里，则不用分，否则划分子集，直到划分不了为止</li>\n<li>:chestnut: 例子</li>\n<li><img data-src=\"/image-6.png\"><br>:::</li>\n</ul>\n",
            "tags": [
                "词法分析"
            ]
        },
        {
            "id": "http://example.com/2025/03/21/computer-science/compile-principles/ch1/",
            "url": "http://example.com/2025/03/21/computer-science/compile-principles/ch1/",
            "title": "Ch1",
            "date_published": "2025-03-20T16:00:00.000Z",
            "content_html": "<blockquote>\n<p>ZJU 2025春夏编译原理 学习笔记</p>\n<p>主要基于虎书（<em>Modern Compiler Implementation in C</em>, Andrew W. Appel）</p>\n</blockquote>\n<h1 id=\"CH1-Introduction\"><a href=\"#CH1-Introduction\" class=\"headerlink\" title=\"CH1 Introduction\"></a>CH1 Introduction</h1><ul>\n<li>Two Important Concepts<ul>\n<li>Phases（阶段）</li>\n<li>Interfaces（接口）</li>\n</ul>\n</li>\n</ul>\n<p>方框里的是phase，中间的是interface<br><img data-src=\"/image.png\"><br>各个阶段的描述<br><img data-src=\"/image-1.png\"><img data-src=\"/image-2.png\"></p>\n",
            "tags": [
                "编译原理"
            ]
        },
        {
            "id": "http://example.com/2025/03/21/computer-science/compile-principles/ch5/",
            "url": "http://example.com/2025/03/21/computer-science/compile-principles/ch5/",
            "title": "Ch5",
            "date_published": "2025-03-20T16:00:00.000Z",
            "content_html": "<h1 id=\"语义分析\"><a href=\"#语义分析\" class=\"headerlink\" title=\"语义分析\"></a>语义分析</h1><blockquote>\n<p>绑定，类型检查</p>\n</blockquote>\n<h2 id=\"symbol-table\"><a href=\"#symbol-table\" class=\"headerlink\" title=\"symbol table\"></a>symbol table</h2><ul>\n<li>Functional style: 函数式风格<ul>\n<li>To keep $\\sigma_1$ in pristine condition while creating create $\\sigma_2$ and $\\sigma_3$<br>:::info 方法：<br>persistent BST<br>:::</li>\n</ul>\n</li>\n<li>Imperative style: 命令式风格<ul>\n<li>Modify $\\sigma_1$ until it becomes $\\sigma_2$. </li>\n<li>While $\\sigma_2$ exists, we cannot look things up in $\\sigma_1$. </li>\n<li>When done with $\\sigma_2$, can undo the modification to get $\\sigma_1$ back again.<br>:::info 方法：<br>Hashing<br>:::</li>\n</ul>\n</li>\n</ul>\n",
            "tags": [
                "语义分析"
            ]
        }
    ]
}